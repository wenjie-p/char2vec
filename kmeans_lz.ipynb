{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小组成员：李柱，学号：201921198685；负责对训练好的doc2vec进行Kmeans聚类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 需要训练好宋词的词向量文件（1）不带图像信息的 char2vec_raw.pickle（2）带有图像信息的 char2vec_with_glyce.pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sklearn下的Kmeans进行聚类，并且迭代100次选出最佳的聚类数目K，最后对聚好的类进行可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import pickle\n",
    "import codecs\n",
    "import json\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1，对不带图像信息的 char2vec_raw.pickle 进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cluster  2 : 1606.684887690315\n",
      "n_cluster  3 : 1323.3958780616058\n",
      "n_cluster  4 : 1474.8747347596416\n",
      "n_cluster  5 : 1349.4472861010902\n",
      "n_cluster  6 : 1315.339303607592\n",
      "n_cluster  7 : 1245.1907918708291\n",
      "n_cluster  8 : 1189.9766801705794\n",
      "n_cluster  9 : 1137.847931178393\n",
      "n_cluster  10 : 1085.8069590897062\n",
      "n_cluster  11 : 1041.6904924238152\n",
      "n_cluster  12 : 995.0025699911265\n",
      "n_cluster  13 : 950.9025665252655\n",
      "n_cluster  14 : 910.7148604868655\n",
      "n_cluster  15 : 887.336683632344\n",
      "n_cluster  16 : 863.5384301980218\n",
      "n_cluster  17 : 833.9221712343824\n",
      "n_cluster  18 : 817.9966051717179\n",
      "n_cluster  19 : 783.5135629088419\n",
      "n_cluster  20 : 772.4061841935063\n",
      "n_cluster  21 : 749.0566163389316\n",
      "n_cluster  22 : 727.1669791491415\n",
      "n_cluster  23 : 706.3618862731192\n",
      "n_cluster  24 : 695.4416766602367\n",
      "n_cluster  25 : 683.7847230449879\n",
      "n_cluster  26 : 663.037951727784\n",
      "n_cluster  27 : 654.0745545860922\n",
      "n_cluster  28 : 642.2968582509423\n",
      "n_cluster  29 : 626.6993654701347\n",
      "n_cluster  30 : 621.7245936585186\n",
      "n_cluster  31 : 607.4853373666505\n",
      "n_cluster  32 : 603.4578514950687\n",
      "n_cluster  33 : 593.9732982305615\n",
      "n_cluster  34 : 585.640452486629\n",
      "n_cluster  35 : 567.1729947310649\n",
      "n_cluster  36 : 561.4078043212132\n",
      "n_cluster  37 : 552.4772999219451\n",
      "n_cluster  38 : 543.9979588264168\n",
      "n_cluster  39 : 542.4740029229039\n",
      "n_cluster  40 : 533.6660475513112\n",
      "n_cluster  41 : 524.3900566462295\n",
      "n_cluster  42 : 516.3512713819208\n",
      "n_cluster  43 : 508.5299653150721\n",
      "n_cluster  44 : 504.27248112434194\n",
      "n_cluster  45 : 490.5901234365188\n",
      "n_cluster  46 : 489.1680705961558\n",
      "n_cluster  47 : 482.43846906813206\n",
      "n_cluster  48 : 475.14103938452985\n",
      "n_cluster  49 : 468.9203376364934\n",
      "n_cluster  50 : 466.3959689827206\n",
      "n_cluster  51 : 455.495888622099\n",
      "n_cluster  52 : 451.42142718928693\n",
      "n_cluster  53 : 452.8135697659431\n",
      "n_cluster  54 : 440.53067287223587\n",
      "n_cluster  55 : 436.24457311824045\n",
      "n_cluster  56 : 432.73031959796833\n",
      "n_cluster  57 : 427.6827506534119\n",
      "n_cluster  58 : 421.03318763186735\n",
      "n_cluster  59 : 420.3045055269738\n",
      "n_cluster  60 : 415.6235955020156\n",
      "n_cluster  61 : 409.3186376749082\n",
      "n_cluster  62 : 405.76741781854275\n",
      "n_cluster  63 : 404.7392457863456\n",
      "n_cluster  64 : 399.34157642048365\n",
      "n_cluster  65 : 399.0264644480418\n",
      "n_cluster  66 : 389.53912495651275\n",
      "n_cluster  67 : 384.9124835547754\n",
      "n_cluster  68 : 381.9294292158289\n",
      "n_cluster  69 : 379.7447882226245\n",
      "n_cluster  70 : 378.17153116572274\n",
      "n_cluster  71 : 375.13665144947043\n",
      "n_cluster  72 : 370.43753834397467\n",
      "n_cluster  73 : 367.6431413291096\n",
      "n_cluster  74 : 364.9207942089457\n",
      "n_cluster  75 : 362.71196993926054\n",
      "n_cluster  76 : 357.9924554391\n",
      "n_cluster  77 : 358.1316864940431\n",
      "n_cluster  78 : 354.00243012804594\n",
      "n_cluster  79 : 350.00186111929713\n",
      "n_cluster  80 : 348.340259993317\n",
      "n_cluster  81 : 342.9143211686887\n",
      "n_cluster  82 : 340.55714975732167\n",
      "n_cluster  83 : 339.52808889517223\n",
      "n_cluster  84 : 337.20007175968664\n",
      "n_cluster  85 : 336.09513860582183\n",
      "n_cluster  86 : 333.34385990362443\n",
      "n_cluster  87 : 329.8425549602116\n",
      "n_cluster  88 : 327.12220251670055\n",
      "n_cluster  89 : 327.7994924355888\n",
      "n_cluster  90 : 322.1480709914656\n",
      "n_cluster  91 : 322.45741551755526\n",
      "n_cluster  92 : 317.60012924548045\n",
      "n_cluster  93 : 315.0743308977623\n",
      "n_cluster  94 : 316.1283837612006\n",
      "n_cluster  95 : 311.98894502809577\n",
      "n_cluster  96 : 311.22610058173336\n",
      "n_cluster  97 : 306.8656066852348\n",
      "n_cluster  98 : 305.50526038841576\n",
      "n_cluster  99 : 305.94528300188693\n",
      "optimal K： 2\n",
      "calinski_harabasz_score: 1606.684887690315\n"
     ]
    }
   ],
   "source": [
    "#读取训练好的词向量文件\n",
    "fin = \"/tmp/char2vec/char2vec_raw.pickle\"\n",
    "fp = codecs.open(fin, \"rb\")\n",
    "dic = pickle.load(fp)\n",
    "# X 用于存放所有宋词的doc2vec \n",
    "X = []\n",
    "for i in dic:\n",
    "        X.append(dic[i][\"doc2vec\"])\n",
    "# 将 X 转化成 array类型\n",
    "X = np.array(X)\n",
    "\n",
    "#迭代100次 选出分数最高的聚类总数K\n",
    "max = 0\n",
    "for j in range(2,100):\n",
    "    n_clusters = j\n",
    "    y_pred = KMeans(n_clusters, random_state=4).fit_predict(X)\n",
    "    # 用calinski_harabasz_score 对聚类结果进行评估\n",
    "    error = metrics.calinski_harabasz_score(X,y_pred)\n",
    "    if error > max:\n",
    "        max = error\n",
    "        index = j\n",
    "    print(\"n_cluster \", j, \":\",error)\n",
    "n_clusters = index\n",
    "print(\"optimal K：\",index)\n",
    "print(\"calinski_harabasz_score:\", max )\n",
    "y_pred = KMeans(n_clusters, random_state=4).fit_predict(X)\n",
    "y_raw = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2,对带有图像信息的 char2vec_with_glyce.pickle进行聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_cluster  2 : 1272.5804104586932\n",
      "n_cluster  3 : 1732.4841830335572\n",
      "n_cluster  4 : 1874.0202198749914\n",
      "n_cluster  5 : 2333.967084934904\n",
      "n_cluster  6 : 2258.827093717251\n",
      "n_cluster  7 : 2165.312471810857\n",
      "n_cluster  8 : 2098.095962642708\n",
      "n_cluster  9 : 2012.2320454524731\n",
      "n_cluster  10 : 1929.0795323415184\n",
      "n_cluster  11 : 1847.0013697224115\n",
      "n_cluster  12 : 1736.553571356158\n",
      "n_cluster  13 : 1652.1896182796856\n",
      "n_cluster  14 : 1556.217257549349\n",
      "n_cluster  15 : 1473.16024191813\n",
      "n_cluster  16 : 1402.3389950561175\n",
      "n_cluster  17 : 1331.8666549936288\n",
      "n_cluster  18 : 1272.2602371573855\n",
      "n_cluster  19 : 1221.9230916873842\n",
      "n_cluster  20 : 1160.0910372490061\n",
      "n_cluster  21 : 1144.4627935180204\n",
      "n_cluster  22 : 1098.1523257061745\n",
      "n_cluster  23 : 1056.405858094966\n",
      "n_cluster  24 : 1020.1191845969091\n",
      "n_cluster  25 : 989.0250651958409\n",
      "n_cluster  26 : 950.082509982724\n",
      "n_cluster  27 : 929.3073974042421\n",
      "n_cluster  28 : 897.1027308055019\n",
      "n_cluster  29 : 872.2436286887425\n",
      "n_cluster  30 : 849.6230802272958\n",
      "n_cluster  31 : 825.2505925683519\n",
      "n_cluster  32 : 806.4542845510678\n",
      "n_cluster  33 : 786.3211449688462\n",
      "n_cluster  34 : 766.9069844669025\n",
      "n_cluster  35 : 755.4118867247763\n",
      "n_cluster  36 : 731.6087040538955\n",
      "n_cluster  37 : 716.5292378310974\n",
      "n_cluster  38 : 702.2300661901672\n",
      "n_cluster  39 : 688.1277493063228\n",
      "n_cluster  40 : 671.5143523419879\n",
      "n_cluster  41 : 660.5662262909387\n",
      "n_cluster  42 : 646.369908898725\n",
      "n_cluster  43 : 632.3766628192064\n",
      "n_cluster  44 : 624.4649752927498\n",
      "n_cluster  45 : 612.6320859856353\n",
      "n_cluster  46 : 599.5052140196451\n",
      "n_cluster  47 : 588.8182555406555\n",
      "n_cluster  48 : 576.9887044534831\n",
      "n_cluster  49 : 570.1115438736163\n",
      "n_cluster  50 : 561.353449577873\n",
      "n_cluster  51 : 552.5716488845308\n",
      "n_cluster  52 : 540.5169617693645\n",
      "n_cluster  53 : 534.5141541272229\n",
      "n_cluster  54 : 526.8615531199599\n",
      "n_cluster  55 : 517.344373813569\n",
      "n_cluster  56 : 508.4068444876268\n",
      "n_cluster  57 : 503.330452441194\n",
      "n_cluster  58 : 494.9153473686398\n",
      "n_cluster  59 : 486.82698520491107\n",
      "n_cluster  60 : 481.67069724789604\n",
      "n_cluster  61 : 474.28227561197434\n",
      "n_cluster  62 : 467.82557352571325\n",
      "n_cluster  63 : 462.17047376667966\n",
      "n_cluster  64 : 456.5056918357829\n",
      "n_cluster  65 : 448.460884725041\n",
      "n_cluster  66 : 447.1732404681349\n",
      "n_cluster  67 : 439.8977009225782\n",
      "n_cluster  68 : 435.0677815293717\n",
      "n_cluster  69 : 428.80546820927316\n",
      "n_cluster  70 : 423.51666910345295\n",
      "n_cluster  71 : 420.1036821888473\n",
      "n_cluster  72 : 412.6555071597986\n",
      "n_cluster  73 : 407.4021527044709\n",
      "n_cluster  74 : 405.3227650818735\n",
      "n_cluster  75 : 403.0658880841771\n",
      "n_cluster  76 : 396.0783932757468\n",
      "n_cluster  77 : 394.997232920828\n",
      "n_cluster  78 : 387.4975756298969\n",
      "n_cluster  79 : 383.9421686548209\n",
      "n_cluster  80 : 380.9902864629808\n",
      "n_cluster  81 : 375.71756919050506\n",
      "n_cluster  82 : 372.0145923435683\n",
      "n_cluster  83 : 369.2532059769911\n",
      "n_cluster  84 : 364.72482362478615\n",
      "n_cluster  85 : 359.9404176479012\n",
      "n_cluster  86 : 357.7941224924986\n",
      "n_cluster  87 : 354.7292506931046\n",
      "n_cluster  88 : 351.73959474186034\n",
      "n_cluster  89 : 348.6650091834423\n",
      "n_cluster  90 : 344.3960230075695\n",
      "n_cluster  91 : 340.78009497927854\n",
      "n_cluster  92 : 338.3147214132212\n",
      "n_cluster  93 : 336.77550842698474\n",
      "n_cluster  94 : 332.18105004337644\n",
      "n_cluster  95 : 330.41228229307654\n",
      "n_cluster  96 : 327.08945660463\n",
      "n_cluster  97 : 323.7656895807136\n",
      "n_cluster  98 : 322.46752039431817\n",
      "n_cluster  99 : 319.92885495973303\n",
      "optimal K： 5\n",
      "calinski_harabasz_score: 2333.967084934904\n"
     ]
    }
   ],
   "source": [
    "#读取训练好的词向量文件\n",
    "fin = \"/tmp/char2vec/char2vec_with_glyce.pickle\"\n",
    "fp = codecs.open(fin, \"rb\")\n",
    "dic = pickle.load(fp)\n",
    "# X 用于存放所有宋词的doc2vec \n",
    "X = []\n",
    "for i in dic:\n",
    "        X.append(dic[i][\"doc2vec\"])\n",
    "# 将 X 转化成 array类型\n",
    "X = np.array(X)\n",
    "\n",
    "#迭代100次 选出分数最高的聚类总数K\n",
    "max = 0\n",
    "for j in range(2,100):\n",
    "    n_clusters = j\n",
    "    y_pred = KMeans(n_clusters, random_state=4).fit_predict(X)\n",
    "    # 用calinski_harabasz_score 对聚类结果进行评估\n",
    "    error = metrics.calinski_harabasz_score(X,y_pred)\n",
    "    if error > max:\n",
    "        max = error\n",
    "        index = j\n",
    "    print(\"n_cluster \", j, \":\",error)\n",
    "n_clusters = index\n",
    "print(\"optimal K：\",index)\n",
    "print(\"calinski_harabasz_score:\", max )\n",
    "y_pred = KMeans(n_clusters, random_state=4).fit_predict(X)\n",
    "y_glyce = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3,对聚类结果（以加图像信息的char2vec_with_glyce.pickle为例）进行可视化（生成json文件在d3中进行可视化）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 注意由于聚类结果的类别较少，每个类别中的宋词数目，在可视化中较困难，所以对含有较多宋词数目类别进行随机取样（随机该类别中100首宋词进行可视化）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main1(data, num):\n",
    "    \"\"\"\n",
    "    实现从data中随机取num个元素，生成一个新的列表\n",
    "    原因是把聚类的全部结果加进去，文件会很大（可视化不支持）\n",
    "    \"\"\"\n",
    "    return random.sample(data, num)\n",
    "\n",
    "# posion 存放每个类别的元素在宋词的序号\n",
    "position = {}\n",
    "num = {}\n",
    "for key in y_pred:\n",
    "    num[key] = num.get(key,0) + 1\n",
    "    position[key] = []\n",
    "for i in range(len(y_glyce)):\n",
    "    position[y_glyce[i]].append(i)\n",
    "    \n",
    "    \n",
    "dictionary = {}\n",
    "dictionary[\"name\"] = \"poems\"\n",
    "#dic[\"children\"] 是个列表，列表的数量为聚类后的类别数量，列表中的每个元素为一个类\n",
    "dictionary[\"children\"] = []\n",
    "\n",
    "# 对于类别2，3，所含的宋词数量较少不需要随机取样\n",
    "for n in [2,3]:\n",
    "    name = \"cluster{}\".format(n)\n",
    "    # sub_dic这个字典代表一个类别\n",
    "    sub_dic = {}\n",
    "    # 当前第i个类别名字为cluster${i}\n",
    "    sub_dic[\"name\"] = name\n",
    "    # sub_dic[\"children\"]为列表，列表长度为当前类别样本数量，列表每个元素为属于这个类别的样本\n",
    "    sub_dic[\"children\"] = []\n",
    "    for i in range(len(position[n])):\n",
    "        if position[n][i] in dic:\n",
    "            sub_name = \"{}\".format(dic[position[n][i]][\"author\"]+ \"-\" + dic[position[n][i]][\"rhythmic\"])\n",
    "            sub_value = i\n",
    "        # 样本名字为 name${i}，名字为”作者-词牌名“ \n",
    "        # value数值不重要，随意给\n",
    "            sub_dic[\"children\"].append({\"name\": sub_name, \"value\": sub_value})\n",
    "        dictionary[\"children\"].append(sub_dic)\n",
    "\n",
    "# 对于类别0，1，4，所含的宋词数量较多（全部可视化较困难，所以随即取出每个类别中的100个宋词）        \n",
    "for n in [0,1,4]:\n",
    "    name = \"cluster{}\".format(n)\n",
    "    # sub_dic这个字典代表一个类别\n",
    "    sub_dic = {}\n",
    "    # 当前第i个类别名字为cluster${i}\n",
    "    sub_dic[\"name\"] = name\n",
    "    # sub_dic[\"children\"]为列表，列表长度为当前类别样本数量，列表每个元素为属于这个类别的样本\n",
    "    sub_dic[\"children\"] = []\n",
    "    cluster_num = []\n",
    "    cluster_num = main1(position[n],100)\n",
    "    for i in range(len(cluster_num)):\n",
    "        if position[n][i] in dic:\n",
    "            sub_name = \"{}\".format(dic[position[n][i]][\"author\"]+ \"-\" + dic[position[n][i]][\"rhythmic\"])\n",
    "            sub_value = i\n",
    "        # 样本名字为 name${i}，名字为”作者-词牌名“\n",
    "        # value数值不重要，随意给\n",
    "            sub_dic[\"children\"].append({\"name\": sub_name, \"value\": sub_value})\n",
    "        dictionary[\"children\"].append(sub_dic)\n",
    "\n",
    "clusters = dictionary[\"children\"]\n",
    "s = []\n",
    "for key in clusters:\n",
    "    if key not in s:\n",
    "        s.append(key)\n",
    "dictionary[\"children\"] = s\n",
    "\n",
    "fp = codecs.open(\"poem.json\", \"w\", encoding = \"utf8\")\n",
    "json.dump(dictionary, fp, ensure_ascii = False)\n",
    "fp.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 最后在 https://observablehq.com/@d3/cluster-dendrogram 上传生成的poem.json文件进行聚类可视化"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
